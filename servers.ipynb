{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from erddapy import ERDDAP # /anaconda3/envs/colocators-ohw19/lib/python3.7/site-packages/erddapy\n",
    "from erddapy import utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib\n",
    "import requests\n",
    "file = urllib.request.urlopen('https://raw.githubusercontent.com/IrishMarineInstitute/search-erddaps/master/erddaps.json')\n",
    "all_servers = json.loads(file.read())\n",
    "#file.getcode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "servers=all_servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del servers[16] # skipping scoos server\n",
    "#del servers[4]\n",
    "len(servers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_min = '2016-07-10T00:00:00Z'\n",
    "time_max = '2016-08-10T00:00:00Z'\n",
    "bbox = [-72.0, -69, 38, 41]\n",
    "\n",
    "kw = {\n",
    "   'search_for': 'all',\n",
    "   'min_lon': bbox[0],\n",
    "   'max_lon': bbox[1],\n",
    "   'min_lat': bbox[2],\n",
    "   'max_lat': bbox[3],\n",
    "   'min_time': time_min,\n",
    "   'max_time': time_max,\n",
    "   'standard_name': 'depth'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "all_datasets=pd.DataFrame()\n",
    "\n",
    "for key in servers:\n",
    "    url = key['url']\n",
    "    url = url.rstrip(\"/\")\n",
    "    e = ERDDAP(\n",
    "                 server=url,\n",
    "                 protocol='tabledap',\n",
    "                 response='csv'\n",
    "           )\n",
    "    r = requests.get(e.get_search_url(**kw))\n",
    "    try:\n",
    "        r.raise_for_status()\n",
    "        print(e.get_search_url(**kw))\n",
    "        ds = pd.read_csv('%s'%e.get_search_url(**kw))\n",
    "        ds['server'] = url\n",
    "    \n",
    "        datasets = ds[['server','Dataset ID','tabledap','Institution','Summary']]\n",
    "    \n",
    "        datasets.dropna(subset=['tabledap'],inplace=True)\n",
    "    \n",
    "        all_datasets = pd.concat([all_datasets,datasets])\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(\"Bad ERDDAP!!! {}\".format(url))\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print(\"Bad ERDDAP!!! {}\".format(url))\n",
    "    except requests.exceptions.ConnectionError as err:\n",
    "        print(\"Bad ERDDAP!!! {}\".format(url))\n",
    "    except requests.exceptions.Timeout as err:\n",
    "        print(\"Bad ERDDAP!!! {}\".format(url))\n",
    "    except requests.exceptions.ConnectTimeout as err:\n",
    "        print(\"Bad ERDDAP!!! {}\").format(url)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%i datasets found.' %all_datasets.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coords = pd.DataFrame()\n",
    "for i in range(all_datasets.shape[0]):\n",
    "    server_url = all_datasets['server'].iloc[int(i)]\n",
    "    dataset_id = all_datasets['Dataset ID'].iloc[int(i)]\n",
    "    \n",
    "    if \"ROMS\" in dataset_id or \"DOP\" in dataset_id: # skip ROMS model output\n",
    "        print(\"Skipping %s\" % server_url + dataset_id)\n",
    "        continue\n",
    "    print(i)\n",
    "    e2 = ERDDAP(\n",
    "                 server=server_url,\n",
    "                 protocol='tabledap',\n",
    "                 response='csv'\n",
    "           )\n",
    "    e2.variables=[\"latitude\",\"longitude\"]#,\"time\"]\n",
    "    e2.dataset_id = all_datasets['Dataset ID'].iloc[int(i)]\n",
    "    #e2.constraints = kw\n",
    "    e2.constraints = {\n",
    "           \"time>=\": time_min,\n",
    "           \"time<=\": time_max,\n",
    "           \"longitude>=\": bbox[0],\n",
    "           \"longitude<=\": bbox[1],\n",
    "           \"latitude>=\": bbox[2],\n",
    "           \"latitude<=\": bbox[3],\n",
    "           \"distinct\" : ()\n",
    "    }\n",
    "    r = requests.get(e2.get_download_url())\n",
    "    try:\n",
    "        r.raise_for_status()\n",
    "        print(e2.get_download_url())\n",
    "        df = e2.to_pandas()\n",
    "        print(\"Found %i unique coordinates.\" % df.shape[0])\n",
    "        df['dataset_count'] = i\n",
    "        df['dataset_download_url'] = e2.get_download_url()\n",
    "        df['Dataset ID'] = dataset_id\n",
    "\n",
    "        df_coords = pd.concat([df_coords,df])\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(\"HTTPError data not within bounds!!! {}\".format(e2.get_download_url()))\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print(\"RequestException data not within bounds!!! {}\".format(e2.get_download_url()))\n",
    "    except requests.exceptions.ConnectionError as err:\n",
    "        print(\"ConnectionError data not within bounds!!! {}\".format(e2.get_download_url()))\n",
    "    except requests.exceptions.Timeout as err:\n",
    "        print(\"Timeout data not within bounds!!! {}\".format(e2.get_download_url()))\n",
    "    except requests.exceptions.ConnectTimeout as err:\n",
    "        print(\"ConnectionTimeout data not within bounds!!! {}\".format(e2.get_download_url()))\n",
    "    \n",
    "\n",
    "    #print(e.get_download_url(response=\"csv\"))\n",
    "    \n",
    "    #dataset_url = '%s/tabledap/%s.csvp?latitude,longitude,time&longitude>=-72.0&longitude<=-69&latitude>=38&latitude<=41&time>=1278720000.0&time<=1470787200.0&distinct()' % (all_datasets['server'].iloc[int(i)],all_datasets['Dataset ID'].iloc[int(i)])\n",
    "\n",
    "df_coords.head()\n",
    "print(\"\\n\\nCollected %i unique coordinate pairs from %i datasets\" % \n",
    "      (df_coords.shape[0], len(df_coords['dataset_count'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 12)) #make_map(extent, figsize=(6, 6))\\n\",\n",
    "#add_etopo2(extent, ax)\\n\",\n",
    "plt.scatter(df_coords['longitude (degrees_east)'],\n",
    "               df_coords['latitude (degrees_north)'],\n",
    "               s=3, c=df_coords['dataset_count'].values)\n",
    "plt.colorbar()\n",
    "plt.title(\"%i datasets\" % len(df_coords['dataset_count'].unique()))\n",
    "#df.plot(x='longitude (degrees_east)',y='latitude (degrees_north)')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coords\n",
    "# need to skip ROMS data: http://tds.marine.rutgers.edu/erddap/tabledap/ROMSSobs.htmlTable?latitude,longitude,time&time%3E=1468108800.0&time%3C=1470787200.0&longitude%3E=-72.0&longitude%3C=-69&latitude%3E=38&latitude%3C=41&distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from erddapy import ERDDAP\n",
    "\n",
    "\n",
    "# e = ERDDAP(\n",
    "#   server='https://data.ioos.us/gliders/erddap',\n",
    "#   protocol='tabledap',\n",
    "# )\n",
    "\n",
    "# e.response = 'csv'\n",
    "# e.dataset_id = 'whoi_406-20160902T1700'\n",
    "# e.constraints = {\n",
    "#     'time>=': '2016-07-10T00:00:00Z',\n",
    "#     'time<=': '2017-02-10T00:00:00Z',\n",
    "#     'latitude>=': 38.0,\n",
    "#     'latitude<=': 41.0,\n",
    "#     'longitude>=': -72.0,\n",
    "#     'longitude<=': -69.0,\n",
    "# }\n",
    "# e.variables = [\n",
    "#     'depth',\n",
    "#     'latitude',\n",
    "#     'longitude',\n",
    "#     'salinity',\n",
    "#     'temperature',\n",
    "#     'time',\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     if url != 'http://erddap.emodnet-physics.eu/erddap' and \\\n",
    "#     url != 'https://erddap.marine.ie/erddap' and \\\n",
    "#     url != 'http://oos.soest.hawaii.edu/erddap' and \\\n",
    "#     url != 'http://erddap.secoora.org/erddap' and \\\n",
    "#     url != 'https://ecowatch.ncddc.noaa.gov/erddap' and \\\n",
    "#     url != 'http://dap.onc.uvic.ca/erddap':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laturl = 'http://erddap.bco-dmo.org/erddap/categorize/variableName/latitude/index.csv'\n",
    "# lonurl = 'http://erddap.bco-dmo.org/erddap/categorize/variableName/longitude/index.csv'\n",
    "\n",
    "# df_lat = pd.read_csv(laturl, header=[0])\n",
    "# df_lon = pd.read_csv(lonurl, header=[0])\n",
    "\n",
    "# df_datasets = pd.merge(df_lat, df_lon, on='Dataset ID')\n",
    "# df_final = pd.DataFrame(columns=['latitude (degrees_north)', 'longitude (degrees_east)', 'Dataset ID'])\n",
    "\n",
    "# for did in df_datasets['Dataset ID']:\n",
    "#     if did != 'bcodmo_dataset_739309': # remove this once we reload all the datasets again.\n",
    "#         dataset_url = 'http://erddap.bco-dmo.org/erddap/tabledap/%s.csvp?latitude,longitude&distinct()' % did\n",
    "#         df_data = pd.read_csv(dataset_url, header=0, usecols=['latitude (degrees_north)', 'longitude (degrees_east)'])\n",
    "#         df_data['Dataset ID'] = did\n",
    "#         df_final = pd.concat([df_final, df_data], sort=False, ignore_index=True)\n",
    "#         print(df_final.shape)\n",
    "\n",
    "# lon = df_final['longitude (degrees_east)'].values\n",
    "# lat = df_final['latitude (degrees_north)'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.14.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
